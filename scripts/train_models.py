"""
æ¨¡å‹è®­ç»ƒè„šæœ¬
è‡ªåŠ¨åŒ–è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹
"""

import asyncio
import logging
import json
import sys
from pathlib import Path
from typing import List, Dict, Any
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from backend.ml_models.project_classifier import ProjectClassifier
from backend.ml_models.feature_extractor import FeatureExtractor
from config import settings

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler(Path(settings.MODEL_CACHE_DIR).parent / "training.log"),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)


def generate_training_data() -> List[Dict[str, Any]]:
    """ç”Ÿæˆè®­ç»ƒæ•°æ®"""
    logger.info("ç”Ÿæˆè®­ç»ƒæ•°æ®...")
    
    training_data = []
    
    # é¡¹ç›®åˆ†ç±»è®­ç»ƒæ•°æ®
    category_examples = [
        {
            "name": "ç”µå•†ç½‘ç«™å¼€å‘",
            "description": "ä½¿ç”¨Reactå’ŒNode.jsæ„å»ºçš„åœ¨çº¿è´­ç‰©å¹³å°",
            "category": "web_development",
            "tech_stack": ["javascript", "react", "nodejs", "mongodb"]
        },
        {
            "name": "ç§»åŠ¨å¥åº·åº”ç”¨",
            "description": "åŸºäºFlutterçš„å¥åº·ç›‘æµ‹å’Œè¿åŠ¨è¿½è¸ªåº”ç”¨",
            "category": "mobile_app",
            "tech_stack": ["dart", "flutter", "firebase"]
        },
        {
            "name": "é”€å”®æ•°æ®åˆ†æ",
            "description": "ä½¿ç”¨Pythonå’ŒPandasè¿›è¡Œé”€å”®æ•°æ®åˆ†æå’Œå¯è§†åŒ–",
            "category": "data_science",
            "tech_stack": ["python", "pandas", "numpy", "matplotlib"]
        },
        {
            "name": "å›¾åƒè¯†åˆ«ç³»ç»Ÿ",
            "description": "åŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒåˆ†ç±»å’Œç‰©ä½“è¯†åˆ«ç³»ç»Ÿ",
            "category": "machine_learning",
            "tech_stack": ["python", "tensorflow", "opencv", "numpy"]
        },
        {
            "name": "æ™ºèƒ½å®¶å±…æ§åˆ¶",
            "description": "ä½¿ç”¨ESP32å’ŒMQTTåè®®çš„æ™ºèƒ½å®¶å±…æ§åˆ¶ç³»ç»Ÿ",
            "category": "iot",
            "tech_stack": ["c++", "arduino", "mqtt", "esp32"]
        },
        {
            "name": "åŒºå—é“¾äº¤æ˜“å¹³å°",
            "description": "åŸºäºä»¥å¤ªåŠçš„åŠ å¯†è´§å¸äº¤æ˜“å’Œæ™ºèƒ½åˆçº¦å¹³å°",
            "category": "blockchain",
            "tech_stack": ["solidity", "ethereum", "web3", "javascript"]
        },
        {
            "name": "2Dæ¸¸æˆå¼€å‘",
            "description": "ä½¿ç”¨Unityå¼•æ“å¼€å‘çš„2Då¹³å°è·³è·ƒæ¸¸æˆ",
            "category": "game_development",
            "tech_stack": ["c#", "unity", "blender"]
        },
        {
            "name": "æ¡Œé¢æ–‡ä»¶ç®¡ç†",
            "description": "ä½¿ç”¨Electronå¼€å‘çš„è·¨å¹³å°æ¡Œé¢æ–‡ä»¶ç®¡ç†å·¥å…·",
            "category": "desktop_application",
            "tech_stack": ["javascript", "electron", "nodejs"]
        },
        {
            "name": "åµŒå…¥å¼æ§åˆ¶ç³»ç»Ÿ",
            "description": "åŸºäºSTM32çš„å·¥ä¸šè®¾å¤‡æ§åˆ¶ç³»ç»Ÿ",
            "category": "embedded_systems",
            "tech_stack": ["c", "stm32", "freertos"]
        },
        {
            "name": "å¾®æœåŠ¡æ¶æ„",
            "description": "ä½¿ç”¨Kuberneteså’ŒDockerçš„å¾®æœåŠ¡äº‘å¹³å°",
            "category": "cloud_infrastructure",
            "tech_stack": ["docker", "kubernetes", "go", "postgresql"]
        }
    ]
    
    # ä¸ºæ¯ä¸ªç±»åˆ«ç”Ÿæˆæ›´å¤šå˜ä½“
    for example in category_examples:
        # åŸå§‹ç¤ºä¾‹
        training_data.append(example)
        
        # å˜ä½“1ï¼šç®€åŒ–æè¿°
        variant1 = example.copy()
        variant1["description"] = f"è¿™æ˜¯ä¸€ä¸ª{example['category']}é¡¹ç›®"
        training_data.append(variant1)
        
        # å˜ä½“2ï¼šä¸åŒæŠ€æœ¯æ ˆ
        variant2 = example.copy()
        variant2["tech_stack"] = [tech + "-variant" for tech in example["tech_stack"][:2]]
        training_data.append(variant2)
        
        # å˜ä½“3ï¼šæ‰©å±•æè¿°
        variant3 = example.copy()
        variant3["description"] = f"è¿™æ˜¯ä¸€ä¸ªé«˜çº§{example['category']}é¡¹ç›®ï¼Œä½¿ç”¨äº†ç°ä»£æŠ€æœ¯æ ˆå’Œæœ€ä½³å®è·µ"
        training_data.append(variant3)
    
    logger.info(f"ç”Ÿæˆäº† {len(training_data)} ä¸ªè®­ç»ƒæ ·æœ¬")
    return training_data


async def train_project_classifier(training_data: List[Dict[str, Any]]) -> Dict[str, Any]:
    """è®­ç»ƒé¡¹ç›®åˆ†ç±»å™¨"""
    try:
        logger.info("å¼€å§‹è®­ç»ƒé¡¹ç›®åˆ†ç±»å™¨...")
        
        classifier = ProjectClassifier()
        
        # å‡†å¤‡åˆ†ç±»å™¨è®­ç»ƒæ•°æ®
        classifier_training = []
        for item in training_data:
            text = f"{item['name']} {item['description']} {' '.join(item['tech_stack'])}"
            classifier_training.append({
                "text": text,
                "label": item["category"]
            })
        
        # è®­ç»ƒæ¨¡å‹
        result = await classifier.train_model(classifier_training)
        
        logger.info(f"é¡¹ç›®åˆ†ç±»å™¨è®­ç»ƒå®Œæˆ: {result}")
        return result
        
    except Exception as e:
        logger.error(f"è®­ç»ƒé¡¹ç›®åˆ†ç±»å™¨å¤±è´¥: {e}")
        return {"error": str(e)}


async def train_feature_extractor(training_data: List[Dict[str, Any]]) -> Dict[str, Any]:
    """è®­ç»ƒç‰¹å¾æå–å™¨"""
    try:
        logger.info("å¼€å§‹è®­ç»ƒç‰¹å¾æå–å™¨...")
        
        feature_extractor = FeatureExtractor()
        await feature_extractor.load_model()
        
        # è®­ç»ƒæ¨¡å‹
        result = await feature_extractor.train_model(training_data)
        
        logger.info(f"ç‰¹å¾æå–å™¨è®­ç»ƒå®Œæˆ: {result}")
        return result
        
    except Exception as e:
        logger.error(f"è®­ç»ƒç‰¹å¾æå–å™¨å¤±è´¥: {e}")
        return {"error": str(e)}


async def evaluate_models(training_data: List[Dict[str, Any]]) -> Dict[str, Any]:
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    try:
        logger.info("å¼€å§‹è¯„ä¼°æ¨¡å‹æ€§èƒ½...")
        
        from backend.ml_models import ProjectClassifier
        
        classifier = ProjectClassifier()
        await classifier.load_model()
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®ï¼ˆä½¿ç”¨å20%ä½œä¸ºæµ‹è¯•é›†ï¼‰
        test_size = max(1, len(training_data) // 5)
        test_data = training_data[-test_size:]
        
        evaluation_results = []
        
        for test_item in test_data:
            try:
                # æµ‹è¯•åˆ†ç±»å™¨
                classification = await classifier.predict(test_item)
                
                evaluation_results.append({
                    "project": test_item["name"],
                    "true_category": test_item["category"],
                    "predicted_category": classification.get("name", "unknown"),
                    "confidence": classification.get("confidence", 0.0),
                    "correct": classification.get("name", "unknown") == test_item["category"]
                })
                
            except Exception as e:
                logger.error(f"è¯„ä¼°é¡¹ç›®å¤±è´¥ {test_item['name']}: {e}")
        
        # è®¡ç®—å‡†ç¡®ç‡
        if evaluation_results:
            correct_count = sum(1 for r in evaluation_results if r["correct"])
            accuracy = correct_count / len(evaluation_results)
            
            logger.info(f"æ¨¡å‹è¯„ä¼°å®Œæˆï¼Œå‡†ç¡®ç‡: {accuracy:.2%}")
            
            return {
                "accuracy": accuracy,
                "total_tests": len(evaluation_results),
                "correct_predictions": correct_count,
                "details": evaluation_results
            }
        else:
            return {"error": "æ²¡æœ‰æœ‰æ•ˆçš„è¯„ä¼°æ•°æ®"}
        
    except Exception as e:
        logger.error(f"è¯„ä¼°æ¨¡å‹å¤±è´¥: {e}")
        return {"error": str(e)}


def save_training_report(results: Dict[str, Any], output_path: Path):
    """ä¿å­˜è®­ç»ƒæŠ¥å‘Š"""
    try:
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"è®­ç»ƒæŠ¥å‘Šä¿å­˜åˆ°: {output_path}")
        
    except Exception as e:
        logger.error(f"ä¿å­˜è®­ç»ƒæŠ¥å‘Šå¤±è´¥: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    try:
        logger.info("=" * 60)
        logger.info("å¼€å§‹è‡ªåŠ¨åŒ–æ¨¡å‹è®­ç»ƒ")
        logger.info("=" * 60)
        
        # 1. ç”Ÿæˆè®­ç»ƒæ•°æ®
        training_data = generate_training_data()
        
        # 2. è®­ç»ƒé¡¹ç›®åˆ†ç±»å™¨
        classifier_result = await train_project_classifier(training_data)
        
        # 3. è®­ç»ƒç‰¹å¾æå–å™¨
        feature_result = await train_feature_extractor(training_data)
        
        # 4. è¯„ä¼°æ¨¡å‹æ€§èƒ½
        evaluation_result = await evaluate_models(training_data)
        
        # 5. ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š
        results = {
            "training_summary": {
                "training_samples": len(training_data),
                "categories": list(set(item["category"] for item in training_data)),
                "training_timestamp": np.datetime64('now').astype(str)
            },
            "classifier_training": classifier_result,
            "feature_extractor_training": feature_result,
            "model_evaluation": evaluation_result,
            "system_info": {
                "model_cache_dir": str(settings.MODEL_CACHE_DIR),
                "config_version": settings.APP_VERSION
            }
        }
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = Path(settings.MODEL_CACHE_DIR).parent / "training_report.json"
        save_training_report(results, report_path)
        
        # è¾“å‡ºæ‘˜è¦
        logger.info("=" * 60)
        logger.info("æ¨¡å‹è®­ç»ƒå®Œæˆæ‘˜è¦")
        logger.info("=" * 60)
        
        if "accuracy" in evaluation_result:
            logger.info(f"ğŸ“Š æ¨¡å‹å‡†ç¡®ç‡: {evaluation_result['accuracy']:.2%}")
        
        if "perplexity" in feature_result:
            logger.info(f"ğŸ“ˆ ç‰¹å¾æå–å™¨å›°æƒ‘åº¦: {feature_result['perplexity']:.2f}")
        
        logger.info(f"ğŸ“ è®­ç»ƒæŠ¥å‘Š: {report_path}")
        logger.info(f"ğŸ“ æ¨¡å‹ç¼“å­˜: {settings.MODEL_CACHE_DIR}")
        
        logger.info("=" * 60)
        logger.info("æ¨¡å‹è®­ç»ƒæµç¨‹å®Œæˆ!")
        logger.info("=" * 60)
        
        return results
        
    except Exception as e:
        logger.error(f"æ¨¡å‹è®­ç»ƒæµç¨‹å¤±è´¥: {e}")
        return {"error": str(e)}


if __name__ == "__main__":
    # è¿è¡Œè®­ç»ƒæµç¨‹
    results = asyncio.run(main())
    
    # è¾“å‡ºæœ€ç»ˆçŠ¶æ€
    if "error" in results:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {results['error']}")
        sys.exit(1)
    else:
        print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ!")
        
        # æ‰“å°å…³é”®æŒ‡æ ‡
        if "model_evaluation" in results and "accuracy" in results["model_evaluation"]:
            accuracy = results["model_evaluation"]["accuracy"]
            print(f"ğŸ“Š å‡†ç¡®ç‡: {accuracy:.2%}")
        
        print(f"ğŸ“ æŸ¥çœ‹å®Œæ•´æŠ¥å‘Š: {Path(settings.MODEL_CACHE_DIR).parent / 'training_report.json'}")
        sys.exit(0)